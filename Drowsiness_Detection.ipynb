{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For training dataset'''\n",
    "\n",
    "folder_dir_1 = r\"C:\\Users\\satya\\Documents\\Visual Studio Code\\Python files\\Drowsiness Detection\\train\\Closed_Eyes\"\n",
    "closed_img = []\n",
    "for images in os.listdir(folder_dir_1):\n",
    "    # Joining the path and conversion into an array\n",
    "    f = os.path.join(folder_dir_1, images)\n",
    "    image = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "    # For converting RGB image to Grayscale image\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Resizing\n",
    "    image = cv2.resize(image, (100, 100))\n",
    "    closed_img.append(image)\n",
    "\n",
    "\n",
    "folder_dir_2 = r\"C:\\Users\\satya\\Documents\\Visual Studio Code\\Python files\\Drowsiness Detection\\train\\Open_Eyes\"\n",
    "open_img = []\n",
    "for images in os.listdir(folder_dir_2):\n",
    "    # Joining the path and conversion into an array\n",
    "    f = os.path.join(folder_dir_2, images)\n",
    "    image = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "    # For converting RGB image to Grayscale image\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Resizing\n",
    "    image = cv2.resize(image, (100, 100))\n",
    "    open_img.append(image)\n",
    "\n",
    "''''For test dataset'''\n",
    "\n",
    "folder_dir_3 = r\"C:\\Users\\satya\\Documents\\Visual Studio Code\\Python files\\Drowsiness Detection\\test\\closed_eye\"\n",
    "closed_eye_test = []\n",
    "for images in os.listdir(folder_dir_3):\n",
    "    # Joining the path and conversion into an array\n",
    "    f = os.path.join(folder_dir_3, images)\n",
    "    image = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "    # For converting RGB image to Grayscale image\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Resizing\n",
    "    image = cv2.resize(image, (100, 100))\n",
    "    closed_eye_test.append(image)\n",
    "\n",
    "folder_dir_4 = r\"C:\\Users\\satya\\Documents\\Visual Studio Code\\Python files\\Drowsiness Detection\\test\\open_eye\"\n",
    "open_eye_test = []\n",
    "for images in os.listdir(folder_dir_4):\n",
    "    # Joining the path and conversion into an array\n",
    "    f = os.path.join(folder_dir_4, images)\n",
    "    image = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "    # For converting RGB image to Grayscale image\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Resizing\n",
    "    image = cv2.resize(image, (100, 100))\n",
    "    open_eye_test.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close = pd.DataFrame(closed_img)\n",
    "'''For train dataset'''\n",
    "closed_img = np.array(closed_img)\n",
    "open_img = np.array(open_img)\n",
    "\n",
    "X_train = np.concatenate((closed_img, open_img), axis=0)\n",
    "\n",
    "classes = [\"closed_img\", \"open_img\"]\n",
    "Y_train = []\n",
    "for i in range(1500):\n",
    "    Y_train.append(0)\n",
    "\n",
    "for i in range(1500):\n",
    "    Y_train.append(1)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "'''For test dataset'''\n",
    "closed_eye_test = np.array(closed_eye_test)\n",
    "open_eye_test = np.array(open_eye_test)\n",
    "\n",
    "X_test = np.concatenate((closed_eye_test, open_eye_test), axis=0)\n",
    "Y_test = []\n",
    "for i in range(500):\n",
    "    Y_test.append(0)\n",
    "\n",
    "for i in range(500):\n",
    "    Y_test.append(1)\n",
    "\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 100, 100, 3)\n",
      "(3000,)\n",
      "(1000,)\n",
      "(1000, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 25s 258ms/step - loss: 8.2125 - accuracy: 0.8593\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 25s 269ms/step - loss: 0.1137 - accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 26s 275ms/step - loss: 0.0887 - accuracy: 0.9767\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 26s 277ms/step - loss: 0.0498 - accuracy: 0.9873\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 26s 276ms/step - loss: 0.0224 - accuracy: 0.9957\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 26s 276ms/step - loss: 0.0378 - accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 26s 277ms/step - loss: 0.0239 - accuracy: 0.9947\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 26s 276ms/step - loss: 0.0162 - accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 26s 276ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 26s 279ms/step - loss: 0.0044 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13f420a84f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, Y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 68ms/step - loss: 1.3792 - accuracy: 0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3792457580566406, 0.824999988079071]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.92994130e-01, 7.00584194e-03, 6.07643225e-09, 5.73555821e-11,\n",
       "        2.20182206e-12, 1.29272569e-13, 5.86032010e-14, 4.68861006e-10,\n",
       "        1.22180030e-14, 6.52559162e-09],\n",
       "       [9.98710513e-01, 1.28950633e-03, 8.21438384e-09, 2.34132002e-11,\n",
       "        1.33904487e-12, 1.01144821e-13, 1.27182851e-13, 2.88892965e-10,\n",
       "        6.15518048e-15, 8.51080628e-09],\n",
       "       [9.96635973e-01, 3.36403283e-03, 5.52811219e-09, 2.60288874e-11,\n",
       "        1.98288586e-12, 8.13026540e-14, 6.55325607e-14, 2.52648652e-10,\n",
       "        8.41919918e-15, 6.62257094e-09],\n",
       "       [9.96275544e-01, 3.72446794e-03, 1.34149438e-08, 4.94744246e-11,\n",
       "        3.17953628e-12, 3.26867168e-13, 2.44829032e-13, 9.27677768e-10,\n",
       "        1.76543537e-14, 1.44683181e-08],\n",
       "       [9.96294796e-01, 3.70522821e-03, 6.10055029e-09, 2.57690778e-11,\n",
       "        1.81727279e-12, 9.85113141e-14, 6.02609258e-14, 2.82244533e-10,\n",
       "        1.07456785e-14, 7.56161977e-09]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [np.argmax(element) for element in y_pred]\n",
    "classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:5]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f68dd0345951f0cf8ba50f1a3a6916c07782ad147069f612168b176ca281376"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
